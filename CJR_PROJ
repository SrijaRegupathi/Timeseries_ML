import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

np.random.seed(42)

# Time index (hourly data ~ 1 year)
hours = 24 * 365
time = pd.date_range(start="2022-01-01", periods=hours, freq="H")

# Components
trend = np.linspace(50, 80, hours)
daily_seasonality = 10 * np.sin(2 * np.pi * time.hour / 24)
weekly_seasonality = 5 * np.sin(2 * np.pi * time.dayofweek / 7)
temperature = 15 + 10 * np.sin(2 * np.pi * time.dayofyear / 365) + np.random.normal(0, 2, hours)
noise = np.random.normal(0, 3, hours)

load = trend + daily_seasonality + weekly_seasonality + 0.5 * temperature + noise

data = pd.DataFrame({
    "load": load,
    "temperature": temperature,
    "hour": time.hour
}, index=time)

# Lag feature
data["load_lag_1"] = data["load"].shift(1)
data.dropna(inplace=True)

data.head()

plt.figure(figsize=(12,4))
plt.plot(data["load"])
plt.title("Synthetic Electricity Load")
plt.show()

from sklearn.metrics import mean_squared_error, mean_absolute_error

X = data[["temperature", "hour", "load_lag_1"]]
y = data["load"]

initial_train_size = int(len(data) * 0.7)

X_train_init = X.iloc[:initial_train_size]
y_train_init = y.iloc[:initial_train_size]

X_test = X.iloc[initial_train_size:]
y_test = y.iloc[initial_train_size:]

print("Train size:", len(X_train_init))
print("Test size :", len(X_test))

from statsmodels.tsa.statespace.sarimax import SARIMAX

sarima_predictions = []
sarima_actuals = []

history_y = y_train_init.copy()
history_X = X_train_init.copy()

print("SARIMAX walk-forward started")

for i in range(len(X_test)):
    model = SARIMAX(
        history_y,
        exog=history_X,
        order=(1,1,1),
        seasonal_order=(1,1,1,24),
        enforce_stationarity=False,
        enforce_invertibility=False
    )
    model_fit = model.fit(disp=False)

    yhat = model_fit.forecast(
        steps=1,
        exog=X_test.iloc[i:i+1]
    )[0]

    sarima_predictions.append(yhat)
    sarima_actuals.append(y_test.iloc[i])

    history_y = pd.concat([history_y, y_test.iloc[i:i+1]])
    history_X = pd.concat([history_X, X_test.iloc[i:i+1]])

print("SARIMAX completed")

sarima_rmse = mean_squared_error(sarima_actuals, sarima_predictions, squared=False)
sarima_mae = mean_absolute_error(sarima_actuals, sarima_predictions)

print("SARIMAX RMSE:", sarima_rmse)
print("SARIMAX MAE :", sarima_mae)

from sklearn.preprocessing import MinMaxScaler
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense

scaler_X = MinMaxScaler()
scaler_y = MinMaxScaler()

X_scaled = scaler_X.fit_transform(X)
y_scaled = scaler_y.fit_transform(y.values.reshape(-1,1))

def create_sequences(X, y, seq_len=24):
    Xs, ys = [], []
    for i in range(seq_len, len(X)):
        Xs.append(X[i-seq_len:i])
        ys.append(y[i])
    return np.array(Xs), np.array(ys)

SEQ_LEN = 24
X_seq, y_seq = create_sequences(X_scaled, y_scaled, SEQ_LEN)

split = int(0.7 * len(X_seq))
X_train, X_test_lstm = X_seq[:split], X_seq[split:]
y_train, y_test_lstm = y_seq[:split], y_seq[split:]


model = Sequential([
    LSTM(64, input_shape=(SEQ_LEN, X_train.shape[2])),
    Dense(1)
])

model.compile(optimizer="adam", loss="mse")
model.fit(X_train, y_train, epochs=10, batch_size=64, verbose=1)

lstm_preds = model.predict(X_test_lstm)
lstm_preds_inv = scaler_y.inverse_transform(lstm_preds)
y_test_inv = scaler_y.inverse_transform(y_test_lstm)

lstm_rmse = mean_squared_error(y_test_inv, lstm_preds_inv, squared=False)
lstm_mae = mean_absolute_error(y_test_inv, lstm_preds_inv)

print("LSTM RMSE:", lstm_rmse)
print("LSTM MAE :", lstm_mae)

import shap

background = X_train[:100]
explainer = shap.DeepExplainer(model, background)

shap_values = explainer.shap_values(X_test_lstm[:200])

shap.summary_plot(
    shap_values[0],
    X_test_lstm[:200].reshape(200, -1),
    feature_names=["temperature", "hour", "load_lag_1"] * SEQ_LEN
)

results = pd.DataFrame({
    "Model": ["SARIMAX", "LSTM"],
    "RMSE": [sarima_rmse, lstm_rmse],
    "MAE": [sarima_mae, lstm_mae]
})

results


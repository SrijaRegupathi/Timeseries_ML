import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
%matplotlib inline

from sklearn.metrics import mean_absolute_error, mean_squared_error

from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, LSTM, Dense, Attention
from tensorflow.keras.optimizers import Adam

data = pd.read_csv(
    "https://raw.githubusercontent.com/jbrownlee/Datasets/master/airline-passengers.csv"
)

data['Month'] = pd.to_datetime(data['Month'])
data.set_index('Month', inplace=True)
data.columns = ['Passengers']

data['lag_1'] = data['Passengers'].shift(1)
data['lag_2'] = data['Passengers'].shift(2)
data['lag_3'] = data['Passengers'].shift(3)

# Rolling statistics
data['roll_mean_3'] = data['Passengers'].rolling(3).mean()
data['roll_std_3'] = data['Passengers'].rolling(3).std()

# Trend feature
data['trend'] = range(len(data))

data = data.dropna()

plt.figure(figsize=(10,4))
plt.plot(data['Passengers'])
plt.title("Multivariate Time Series Target Variable")
plt.show()

train = data.iloc[:-24]
test = data.iloc[-24:]

test = test.copy()
test['Naive'] = train.iloc[-1]['Passengers']

mae_naive = mean_absolute_error(test['Passengers'], test['Naive'])

features = ['lag_1','lag_2','lag_3','roll_mean_3','roll_std_3','trend']

X_train = train[features]
y_train = train['Passengers']

X_test = test[features]
y_test = test['Passengers']

from sklearn.linear_model import LinearRegression
ml_model = LinearRegression()
ml_model.fit(X_train, y_train)

test['ML_Pred'] = ml_model.predict(X_test)

mae_ml = mean_absolute_error(y_test, test['ML_Pred'])

def create_sequences_multivariate(df, target_col, window=12):
    X, y = [], []
    values = df.values
    target_idx = df.columns.get_loc(target_col)
    for i in range(len(df)-window):
        X.append(values[i:i+window, :])
        y.append(values[i+window, target_idx])
    return np.array(X), np.array(y)

X, y = create_sequences_multivariate(data, 'Passengers', 12)

X_train, X_test = X[:-24], X[-24:]
y_train, y_test = y[:-24], y[-24:]

inputs = Input(shape=(X_train.shape[1], X_train.shape[2]))

lstm_out = LSTM(64, return_sequences=True)(inputs)

attention_out = Attention()([lstm_out, lstm_out])

context = attention_out[:, -1, :]

output = Dense(1)(context)

model = Model(inputs, output)

model.compile(
    optimizer=Adam(0.001),
    loss='mse'
)

model.summary()

history = model.fit(
    X_train, y_train,
    epochs=60,
    batch_size=16,
    validation_split=0.1,
    verbose=1
)

dl_preds = model.predict(X_test).flatten()

mae_dl = mean_absolute_error(y_test, dl_preds)
rmse_dl = np.sqrt(mean_squared_error(y_test, dl_preds))

def mape(y_true, y_pred):
    return np.mean(np.abs((y_true - y_pred)/y_true))*100

mape_dl = mape(y_test, dl_preds)

results = pd.DataFrame({
    'Model': ['Naive Baseline', 'ML Multivariate', 'DL + Attention'],
    'MAE': [mae_naive, mae_ml, mae_dl],
    'RMSE': [np.nan, np.nan, rmse_dl]
})

results

plt.figure(figsize=(10,4))
plt.plot(test.index, y_test, label='Actual')
plt.plot(test.index, dl_preds, label='DL + Attention')
plt.legend()
plt.title("Multivariate DL Forecast with Attention")
plt.show()

attention_model = Model(
    inputs=model.input,
    outputs=model.layers[2].output
)

attention_weights = attention_model.predict(X_test)

import matplotlib.pyplot as plt
plt.imshow(attention_weights[0], cmap='viridis')
plt.colorbar()
plt.title("Attention Weights Across Time Steps")
plt.xlabel("Time Steps")
plt.ylabel("Attention Intensity")
plt.show()
